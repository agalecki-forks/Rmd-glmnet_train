---
title: 'Regularized Cox Regression Model'
author: "Chunyi Wu and Andrzej Galecki"
date: "`r as.character(Sys.Date(), format = '%A %B %d, %Y')`"
output:
  rmdformats::readthedown:
    lightbox: true
    use_bookdown: true
params:
   mod_lbl: "M0" 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment="#>")
mod_lbl <- params$mod_lbl # Model label
```

```{r, data, include = FALSE}
if (!require('pacman')) install.packages('pacman', repos = "http://cran.us.r-project.org")
library(pacman)

pacman::p_load(
  readxl,       # load excel file
  glmnet,       # Lasso and Elastic-Net Regularized Generalized Linear Models
  rmdformats,   # rmd formats
  rmarkdown,    # rmarkdown
  here,         # File locator
  skimr,        # get overview of data
  tidyverse,    # data management + ggplot2 graphics 
  janitor,      # adding totals and percents to tables
  flextable,    # format the output table
  gtsummary,    # calculate summary statistics and format the results
  sjPlot,       # correlation matrix
  purrr,        # enhances R functional programming (FP) toolki 
  tidyr,        #Tools to help to create tidy data
  ggplot2,      #Plot the results
  glmnetUtils,  #Glmnet models for multiple alpha
  coefplot,     # Plotting Model Coefficients
  survival,     #survival model 
  tidymodels,   #for modeling and machine learning using tidyverse principles
  survivalROC   #survivalROC
  )
```

```{r utilsag-version-2test, include = FALSE}
uag_ver0 <- "0.2.1" # utilsag version tested to execute this script
```

This script was (successfully) tested using version *`r uag_ver0`* of the `utilsag` package.

Information on current installation of `utilsag` package is as follows: 

```{r utilsag-info, include = FALSE}
.libPaths()
uag_path <- system.file(package = "utilsag")
uag_ver  <- if (uag_path != ""){
     as.character(packageVersion("utilsag"))} else ""
```

* Path to `utilsag`: `r uag_path` 
* `utilsag` version: *`r uag_ver`* 


```{r install-tested-utilsag, include=FALSE}
uag_ref0 <- paste0("version-", uag_ver0)

if("utilsag" %in% (.packages())) detach("package:utilsag", unload=TRUE)

if (uag_ver != uag_ver0){
   devtools::install_github("agalecki/utilsag", ref = uag_ref0)
}
library(utilsag)
```
 

This script was executed using `utilsag` package stored in Github branch *`r uag_ref0`*,
as needed.



# Introduction (`r mod_lbl`)

In this report we consider Cox regression model `r mod_lbl` for the time-to-event `time` variable. 

<!-- Conditonal text inserted -->  
`r if(mod_lbl == "M0"){
"Model M0 contains baseline HbA1c, log10(ACR), BL_eGFR, SEX, and AGE_TL(Baseline Age) as candidate predictors"
}`

`r if(mod_lbl == "M1"){
"Model M1 contains 21 proteins as candidate predictors."
}`


`r if(mod_lbl == "M2"){
"Model M2 contains 21 proteins and Baseline HbA1c, log10(ACR), BL_eGFR, SEX, and AGE_TL(Baseline Age) as candidate predictors"
}`
<!-- Conditonal text ends --> 

Notes: 

* Originally `time` variable was named `FU_TIME`.  
* `status` (0/1) variable, originally named `CASE_CONTROL`, is coded 0 for Controls (i.e., ESKD event has not occurred), and 1 for Cases (i.e., event has occurred)

## Auxiliary functions

For reference, arguments of selected functions in `utilsag` package are shown below:

```{r  pred-coxnet}
str(formals("pred_censored_coxnet"))
```

## Data prep

Data are prepared for Cox regression.        

```{r, prepare-data, echo=TRUE, message=FALSE, warning=FALSE}
#read the data that is stored under the data folder

dt <- read_excel("./Data/data_example.xlsx")

dt <- dt  %>% rename(time = FU_TIME, status = CASE_CONTROL) %>% 
  mutate(log10_DU_ACR = log10(DU_ACR))  %>% filter(time>0)

dim(dt) # Number of rows and columns in the input data
```
Variable names used in Cox regression model are strored in the following vectors:

* Proteins in `prot_npx`,
* Time/status in `surv_vars`,
* Clinical variables in `clin_vars`

```{r Variables-used-Cox}
prot_npx <- c("KIM1.npx","SYND1.npx","IL.1RT1.npx",   "WFDC2.npx", "CD27.npx",
              "TNFRSF10A.npx","LAYN.npx","PVRL4.npx", "EDA2R.npx","TNFRSF4.npx",
              "GFR_alpha_1_npx","TNF.R1.npx","PI3_npx", "EFNA4.npx","TNF.R2.npx" ,
              "DLL1.npx", "TNFRSF6B.npx", "CD160.npx", "EPHA2.npx","RELT.npx",
              "LTBR.npx") 
surv_vars <-  c("time", "status")
clin_vars <- c("BL_eGFR","B_HBA1C_PRC","log10_DU_ACR","SEX","AGE_TL")
```



Data preparation: 

* Vector `vars`  contains all variable names needed to specify model `r mod_lbl` considered in this document

```{r select-vars, include =FALSE}

if (mod_lbl == "M0") vars <- c(surv_vars, clin_vars) 
if (mod_lbl == "M1") vars <- c(surv_vars, prot_npx, clin_vars) 
if (mod_lbl == "M2") vars <- c(surv_vars,  prot_npx, clin_vars) 

```

```{vars vector}
vars
```

* Create dataset `data` that contains subset of all vars needed for the analytical dataset.

```{r data-prep1}
data <- dt  %>% select(all_of(vars)) 
dim(data)         
```

* Keep rows with complete cases in `data_drop_na` dataframe.


```{r data-prep2}
#drop any records with NA
data_drop_na <- data %>% drop_na()    

#Total sample size
nrow(data_drop_na)
```

* Create X matrix and Surv object

```{r model-mtx}
# Create X matrix
dtx <- subset(data_drop_na, select=-c(time,status))
x <- model.matrix(~0 +., data=dtx)
dim(x)
colnames(x)
#select follow-up time and status
y <- data.matrix(data_drop_na[,c("time", "status")])
ySurv <- survival::Surv(y[,"time"], y[, "status"])
```

* Create cv-folds (nfolda = 10 is default in `cv.glmnet`)

```{r foldid-1}
set.seed(1234)
nfolds <-10
foldid <- sample(1:nfolds, size = nrow(data_drop_na), replace=TRUE)
length(foldid)
```

* Table with fold sizes is provided.

```{r foldid-2}
tibble(foldid = foldid) %>% group_by(foldid) %>% count()



```

# Ridge regression ($\alpha=0$)

Ridge regression using `glmnet`.

## glmnet fit 

Fit the Cox regression model

```{r glmnet-pfit-a0, echo=TRUE, message=FALSE, warning=FALSE}
#fit the cox regression model
pfit_a0 <- glmnet(x, ySurv, family = "cox", alpha=0)
myglance(pfit_a0)
```



## Explore glmnet fit 

Extracting info from glmnet fit ($\alpha=0$)

### Coefficient plots

* Cox Regression Model Coefficient Plot

```{r, pfit_plot, echo=TRUE, message=FALSE, warning=FALSE}
plot(pfit_a0, label = TRUE)
```



## cv.glmnet

Cross validation (C-V) is perfomed using folds defined in `foldid` vector. 

```{r, cv_glmnet-a0, echo=TRUE, message=FALSE, warning=FALSE}
# cross-validate model
cvfit_a0 <- cv.glmnet(x, ySurv, family = "cox", alpha=0, foldid = foldid)
```

### C-V coefficient plot 


* Cross-Validated Cox Regression Model Coefficient Plot
* Note: *a0* used in object names indicates that $\alpha=0$

```{r, cv_plot-a0, echo=TRUE, message=FALSE, warning=FALSE}
plot(cvfit_a0, label = TRUE) 
```

### Examine C-V 

#### Glance 

Glance object `cvfit_a0`.

```{r myglance-cvfit0}
cvfit_a0_myglance <- myglance(cvfit_a0)
colnames(cvfit_a0_myglance)
cvfit_a0_myglance[c("alpha", "lambda.min", "lambda.1se", "index_min" , "index_1se","n_lambda")]
cvfit_a0_myglance[c("alpha","nobs","n_colx", "family")]
cvfit_a0_myglance[["lambda.min"]]
(index_min <- cvfit_a0_myglance[["index_min"]])
```

#### Coefficients

Coefficients for selected $\lambda$s

Cross-Validated Cox Regressionn Coefficients using `lambda.min` value

* Cross check `lmbda_min_a0` with `cvfit_a0_myglance[["lambda.min"]]`

```{r  cv-min-a0, echo=TRUE, message=FALSE, warning=FALSE}
#get the minimal lambda value (value of lambda that gives minimum cvm)
(lmbda_min_a0 <- cvfit_a0$lambda.min)

# Express lambda on natural log scale
log(lmbda_min_a0)
```

Two ways of extracting coefficients for min lambda from object of `cv.glmnet` class

```{r cv-min-a0-coefs}
# Cross-validated Cox Regression Model using the minimal lambda
coef(cvfit_a0, s = "lambda.min")
# coef(cvfit_a0, s = index_min) # Use position 
```

* Cross-Validated Cox Regression Coefficients using `lambda.1se`
* largest value of lambda such that error is within 1 standard error of the minimum.

```{r, cv-lse-a0, echo=TRUE, message=FALSE, warning=FALSE}
(lmbda_1se_a0 <- cvfit_a0$lambda.1se)

# Express on natural log scale
log(lmbda_1se_a0)

coef(cvfit_a0, s = "lambda.1se")
```

Beta coefficients saved 

```{r beta-a0-saved}
b_a0_1se <- coef(cvfit_a0, s = "lambda.1se")
b_a0_min <- coef(cvfit_a0, s = "lambda.min")
```



Use `mytidy()` function to extract estimates of loss function for selected values of lambda

```{r mytidy-cvfit0}
(cvfit_a0_mytidy <- mytidy(cvfit_a0))
cvfit_a0_mytidy %>% filter(step == cvfit_a0_myglance[["index_min"]])
cvfit_a0_mytidy %>% filter(near(lambda, lmbda_min_a0))
cvfit_a0_mytidy %>% filter(step == cvfit_a0_myglance[["index_1se"]])
cvfit_a0_mytidy %>% filter(near(lambda, lmbda_1se_a0))

```

Plot cross-validation curve and upper and lower standard deviation curves along
the $\lambda$ sequence (error bars). Two selected $\lambda$s are indicated by the
vertical dotted lines

```{r cv-curve-plot-a0}
theme_set(theme_minimal())

ggplot(cvfit_a0_mytidy, aes(x = log(lambda), y = estimate)) +
  geom_line() +
  geom_point(size=3, shape=21, fill="red") +   # 21 is filled circle  
  geom_errorbar(aes(ymin=conf.low, ymax=conf.high), width=.1, color="grey") +
  geom_vline(xintercept = log(lmbda_min_a0), color ="blue", linetype="dotted") +
  geom_vline(xintercept = log(lmbda_1se_a0), color ="blue", linetype="dotted") +
  xlab("Log(Lambda)") + ggtitle("C-V curve (alpha=0)")
```

# LASSO ($\alpha=1$)

Least Absolute Shrinkage and Selection operator


## glmnet fit 

```{r glmnet-pfit-a1, echo=TRUE, message=FALSE, warning=FALSE}
#fit the cox regression model
pfit_a1 <- glmnet(x, ySurv, family = "cox", alpha=1)
glance(pfit_a1)
```
## Explore glmnet fit 

Extracting info from glmnet fit ($\alpha=1$)


## cv.glmnet

### C-V coefficient plot ($\alpha=1$)


* Cross-Validated Cox Regression Model Coefficient Plot

```{r, cv_plot-a1, echo=TRUE, message=FALSE, warning=FALSE}

#fit the cross-validatedmodel
cvfit_a1 <- cv.glmnet(x, ySurv, family = "cox", alpha=1, foldid = foldid)
plot(cvfit_a1, label = TRUE) 
```


### Extract info from C-V 

```{r myglance-cvfit1}
cvfit_a1_myglance <- myglance(cvfit_a1)
colnames(cvfit_a1_myglance)
cvfit_a1_myglance
```


* Coefficients for selected $\lambda$s

Cross-Validated Cox Regressionn Coefficients using `lambda.min` value

```{r, cv-min-a1, echo=TRUE, message=FALSE, warning=FALSE}
#get the minimal lambda value (value of lambda that gives minimum cvm)
(lmbda_min_a1 <- cvfit_a1$lambda.min)

# Express on natural log scale
log(lmbda_min_a1)
# Cross-validated Cox Regression Model using the minimal lambda
coef(cvfit_a1, s = "lambda.min")
```

* Cross-Validated Cox Regression Coefficients using `lambda.1se`
* largest value of lambda such that error is within 1 standard error of the minimum.

```{r, cv-lse-a1, echo=TRUE, message=FALSE, warning=FALSE}
(lmbda_1se_a1 <- cvfit_a1$lambda.1se)

# Express on natural log scale
log(lmbda_1se_a1)
```

Beta coefficients saved 

```{r beta-a1-saved}
b_a1_1se <- coef(cvfit_a1, s = "lambda.1se")
b_a1_min <- coef(cvfit_a1, s = "lambda.min")

```

Use mytidy() function to extract additional info on optimal lambdas

```{r mytidy-cvfit1}
(cvfit_a1_mytidy <- mytidy(cvfit_a1))
# cvfit_a1_mytidy %>% filter(step == cvfit_a1_myglance[["index_min"]])
cvfit_a1_mytidy %>% filter(near(lambda, lmbda_min_a1))
# cvfit_a1_mytidy %>% filter(step == cvfit_a1_myglance[["index_1se"]])
cvfit_a1_mytidy %>% filter(near(lambda, lmbda_1se_a1))
```

Plot cross-validation curve and upper and lower standard deviation curves along
the $\lambda$ sequence (error bars). Two selected $\lambda$s are indicated by the
vertical dotted lines

```{r cv-curve-plot-a1}
theme_set(theme_minimal())

ggplot(cvfit_a1_mytidy, aes(x = log(lambda), y = estimate)) +
  geom_line() +
  geom_point(size=3, shape=21, fill="red") +   # 21 is filled circle  
  geom_errorbar(aes(ymin=conf.low, ymax=conf.high), width=.1, color="grey") +
  geom_vline(xintercept = log(lmbda_min_a1), color ="blue", linetype="dotted") +
  geom_vline(xintercept = log(lmbda_1se_a1), color ="blue", linetype="dotted") +
  xlab("Log(Lambda)") + ggtitle("C-V curve (alpha=1)")
```

# Multiple alpha

* glmnetUtils package
* Glmnet models for multiple alpha 
* We use cross-validation to tune hyperparameter $\alpha$.
* The idea of "explicitly control the fold" is implemented in `glmnetUtils` package
* The cva.glmnet function does simultaneous cross-validation for both the $\alpha$ and $\lambda$ parameters in an elastic net model.

source: (https://glmnet.stanford.edu/articles/glmnet.html)

## cva.glmnet

```{r glmnetUtils}

alphv <- seq(0, 1, len = 11)^3
cva_pfit <- cva.glmnet(x=x,y=ySurv,family = "cox", alpha = alphv, foldid = foldid)
minlossplot(cva_pfit)
```


## Explore cva.glmnet
cva_pfit_mytidy$glmnet.cv %>% filter(near(lambda, lmbda_min_a1))

Glance `cva_pfit` object. 

```{r cva-pfit-myglance}
myglance(cva_pfit)
```

Extract optimal (hyper)parameters from `cva.glmnet` object

```{r get_best_params}

(pfit_params <- get_cvaglmnet_params(cva_pfit))

a_opt <- pfit_params[["alpha"]]
lmbda_opt <- pfit_params[["lambdaMin"]]
```

Cox regression coefficients using the best combination of (hyper)parameters

```{r get_best_coef}

b_ax_opt <- coef(cva_pfit, s = lmbda_opt, alpha = a_opt)
```

# Summary

* Summary of selected models

```{r create-sel-models-summary, include = FALSE}
mod_selected <- tribble(
     ~lbl,     ~alpha, ~lambda,
     "a0_min",   0,     lmbda_min_a0,
     "a0_1se",   0,     lmbda_1se_a0,
     "ax_opt",   a_opt, lmbda_opt,
     "a1_min",   1,    lmbda_min_a1,
     "a1_1se",   1,    lmbda_1se_a1,

)
```

```{r sel-models-summary}
mod_selected
```



* Unstandardized beta coefficients for selected models

```{r beta-coefficients-selx, include = FALSE}

beta_selx <- tibble(
    nms      = dimnames(b_a0_min)[[1]],
    a0_min = as.vector(b_a0_min),
    a0_1se = as.vector(b_a0_1se),
    ax_opt = as.vector(b_ax_opt),
    a1_min = as.vector(b_a1_min),
    a1_1se = as.vector(b_a1_1se)
)

```

```{r print-beta-coefficients-selx}
beta_selx %>% print(n=30)
```
## Plotting survival curves for optimal model

See examples at: https://glmnet.stanford.edu/reference/survfit.coxnet.html

Notes: 

* `survfit` computes the predicted survivor function for a Cox PH model with elastic net penalty.
* the design matrix x and response ySurv used to fit the model need to be passed to `survfit` function

* Step 1: Fit the glmnet model to original data (stored in x2 and y2Surv objects) using optimal alpha.
* Note: Resulting object `pfit_aopt` contains models for multiple lambdas. 

```{r pfit2_a-object}
pfit_aopt <- glmnet(x, ySurv, family = "cox", alpha= a_opt)
```

```{r surv2-plot}
# survfit object for penalized Cox model
sfx <- survival::survfit(pfit_aopt, s = lmbda_opt, x = x, y = ySurv)
plot(sfx)
```

Note that the same plot can be obtained using the code below.

```{r surv-plot-mean}
xmean <- apply(x, 2, mean)
sfm <- survival::survfit(pfit_aopt, s = lmbda_opt, x = x, y = ySurv, newx = xmean)
# plot(sfm)
```


# Model Performance

This section should be considered as an illustration only, because the `glmnet` model
performance is assessed using training data. For this reason performance of the model
is too optimistic.


## Preparatory steps

* Step 1.  Object `pfit_aopt` contains model fits for optimal alpha. It was created earlier in this document 
It contains model fits for multiple lambdas. 


Step 2: Prepare test data 

```{r Prepare-test-data}
dim(data_drop_na)
test_rows <- 1:nrow(data_drop_na) # Select rows for testing. Possibly all rows in data_drop_na.
x_test <- x[test_rows,]
y_test <- y[test_rows,]
ySurv_test <- survival::Surv(y_test[,"time"], y_test[,"status"] )

data_test <- data_drop_na[test_rows, ]
range(data_test$time)
```

Step 3: Calculate predicted values for test data

```{r calc-pred2}
predM_lpmtx <- predict(pfit_aopt, newx = x_test, type = "link") # Matrix
predM_lp <- as.vector(predict(pfit_aopt, newx = x_test, type = "link", s = lmbda_opt))
summary(predM_lp)
```

## Predictive performance 

Predictive performance of optimal model 

### C-index

Ref: Harrel Jr, F. E. and Lee, K. L. and Mark, D. B. (1996) Tutorial in biostatistics:
multivariable prognostic models: issues in developing models, evaluating assumptions 
and adequacy, and measuring and reducing error, _Statistics in Medicine_, 15, pages 361-387.


```{r C-index-Mod}
Cindex_lmbda <- apply(predM_lpmtx, 2, Cindex, y = ySurv_test) # Multiple lambda
length(Cindex_lmbda)
Cindex_lmbda[1:12] 

Cindex(predM_lp, ySurv_test)   # For optimal lambda
```

### Time-dependent ROC

* source: (https://datascienceplus.com/time-dependent-roc-for-survival-prediction-models-in-r)


```{r surv-roc}
dataM_test <- data_test
                
## Augment `dataM_test` with linear predictor
 dataM_test$predM_lp <- predM_lp

# Evaluate every 2.5 years
 
tx <- 2.5* c(2,3,4,5,6) # ROC time points
tx
survROC_lp <- create_survivalROC_data(tx, dataM_test, predM_lp)
 
# survROC_lp %>% print (n=100)
```

* Plot Time-dependent ROC every 2.5 years

```{r surv-roc-plot}
## Plot Time-dependent ROC every 2.5 years
plot_timedep_ROC(survROC_lp) 
```


# Tidymodels

Fit optimal models using tidymodels
Based on (https://parsnip.tidymodels.org/reference/details_proportional_hazards_glmnet.html)

```{r tidy-libs}
library(survival)
library(censored)
library(dplyr)
library(tidyr)
```


## Model fits 

Create `mod_all` object.

```{r tidy-Mod-all}
# Model for all alpha
mod_all <- map(alphv, function(a){
  proportional_hazards(penalty = tune(), mixture = a) %>% 
  set_engine("glmnet") %>% 
  fit(Surv(time, status) ~ ., data = data_drop_na)
})
length(mod_all)
tmp <- mod_all[[2]]
class(tmp)
```

* Create `mod_opt` object using optimal set of hyperparameters obtained in earlier section.

```{r tidy-Mod-opt}
print(a_opt)      #  optimal alpha
print(lmbda_opt)  #  optimal lambda

mod_opt <- 
  proportional_hazards(penalty = lmbda_opt, mixture = a_opt) %>% 
  set_engine("glmnet") %>% 
  fit(Surv(time, status) ~ ., data = data_drop_na)
class(mod_opt)
```


# Tidy assessment


Create tibble with predicted values for `r mod_lbl`:
Predicted values are calculated for:

* Linear predictor (`.pred_linear_pred`)
* Survival time (`.pred_time`)
* Survival probabilities at selected time points (`.pred`)

```{r  pred-coxnet-mod-opt}
tst_rows <- 1:nrow(data_drop_na) # Select rows for testing. Possibly all rows in data_drop_na2.
dataM_test <- data_drop_na[tst_rows, ]

pred_M <- pred_censored_coxnet(mod_opt, dataM_test, time_points = c(5,10))
pred_M

pred_M %>% unnest(.pred)
```



```{r Cindex-tidy}
summ_M <- pred_M %>%
                summarize(Cindex = Cindex(.pred_linear_pred, Surv(time, status)))
summ_M$Cindex
```

* Plot predicted  (y-axis) versus observed (x-axis) time to ESKD by status 

```{r plot-predM}
   
range(pred_M$time)
range(pred_M$.pred_time)
pred_Md <- pred_M %>% mutate(diff = .pred_time - time,
                               mx = (.pred_time + time)/2)

ggplot(pred_M, aes(x = time, y= .pred_time)) +
     coord_fixed() +            # ratio parameter defaults to 1
     xlim(0,17) + ylim(0, 17) +
     geom_point(aes(color = factor(status))) +
     geom_segment(aes(x = min(time), y = min(time), xend = max(time), yend = max(time)))

```

```{r plot-timedep-ROC-pred_M}
tx <- 2.5* c(2,3,4,5,6)    # ROC time points 
tx
survROC_data <- create_survivalROC_data(tx, pred_M, .pred_linear_pred)

## Plot Time-dependent ROC every 2.5 years
plot_timedep_ROC(survROC_data) 
```



* save selected objects for post-processing

```{r save-objects}
fpath <- paste0("./save/5.Cox_tidy_", mod_lbl, ".Rdata")
save(cva_pfit, mod_all, mod_opt, alphv, file = fpath)

fpath2 <- paste0("./save/5.Cox_tidy2_", mod_lbl, ".Rdata")
save(mod_selected, cva_pfit, mod_all, file = fpath2)
```

* Reinstall original version of `r "utilsag"` package

```{r reinstall-original-utilsag, include=FALSE}

if (uag_ver != uag_ver0){ # reinstall original utilsag version
    if("utilsag" %in% (.packages())) detach("package:utilsag", unload=TRUE)
    devtools::install_github("agalecki/utilsag", ref =paste0("version-", uag_ver))
}
```
